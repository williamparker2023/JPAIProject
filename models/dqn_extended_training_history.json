[
  {
    "episode": 200,
    "train_reward": -0.21999999999999953,
    "train_steps": 16,
    "eval_score": 1.0,
    "epsilon": 0.7238518318722612
  },
  {
    "episode": 400,
    "train_reward": -1.7500000000000004,
    "train_steps": 112,
    "eval_score": 1.2,
    "epsilon": 0.6549518431310352
  },
  {
    "episode": 600,
    "train_reward": 0.10000000000000098,
    "train_steps": 67,
    "eval_score": 0.8,
    "epsilon": 0.5926101142981421
  },
  {
    "episode": 800,
    "train_reward": -2.51,
    "train_steps": 26,
    "eval_score": 0.6,
    "epsilon": 0.5362023960259251
  },
  {
    "episode": 1000,
    "train_reward": -1.3699999999999999,
    "train_steps": 50,
    "eval_score": 1.2,
    "epsilon": 0.4851638582720763
  },
  {
    "episode": 1200,
    "train_reward": 1.44,
    "train_steps": 23,
    "eval_score": 0.2,
    "epsilon": 0.4389834344605705
  },
  {
    "episode": 1400,
    "train_reward": 0.52,
    "train_steps": 39,
    "eval_score": 0.0,
    "epsilon": 0.397198703994826
  },
  {
    "episode": 1600,
    "train_reward": 3.019999999999999,
    "train_steps": 11,
    "eval_score": 0.0,
    "epsilon": 0.35939126187992837
  },
  {
    "episode": 1800,
    "train_reward": -2.689999999999998,
    "train_steps": 150,
    "eval_score": 0.0,
    "epsilon": 0.3251825290883371
  },
  {
    "episode": 2000,
    "train_reward": 1.02,
    "train_steps": 20,
    "eval_score": 0.0,
    "epsilon": 0.29422996171680904
  },
  {
    "episode": 2200,
    "train_reward": 0.6699999999999995,
    "train_steps": 74,
    "eval_score": 0.0,
    "epsilon": 0.26622362097552177
  },
  {
    "episode": 2400,
    "train_reward": -3.6899999999999973,
    "train_steps": 150,
    "eval_score": 0.0,
    "epsilon": 0.24088306966349723
  },
  {
    "episode": 2600,
    "train_reward": -4.480000000000009,
    "train_steps": 199,
    "eval_score": 0.0,
    "epsilon": 0.2179545640536697
  },
  {
    "episode": 2800,
    "train_reward": 5.139999999999999,
    "train_steps": 13,
    "eval_score": 0.0,
    "epsilon": 0.19720851306896112
  },
  {
    "episode": 3000,
    "train_reward": -2.2300000000000004,
    "train_steps": 193,
    "eval_score": 0.0,
    "epsilon": 0.17843717930721498
  },
  {
    "episode": 3200,
    "train_reward": 2.069999999999999,
    "train_steps": 25,
    "eval_score": 0.0,
    "epsilon": 0.16145259889455837
  },
  {
    "episode": 3400,
    "train_reward": -10.559999999999999,
    "train_steps": 221,
    "eval_score": 0.0,
    "epsilon": 0.14608469933795434
  },
  {
    "episode": 3600,
    "train_reward": -4.300000000000001,
    "train_steps": 138,
    "eval_score": 0.0,
    "epsilon": 0.13217959653035824
  },
  {
    "episode": 3800,
    "train_reward": 2.0399999999999943,
    "train_steps": 141,
    "eval_score": 0.0,
    "epsilon": 0.11959805385579514
  },
  {
    "episode": 4000,
    "train_reward": -8.610000000000005,
    "train_steps": 266,
    "eval_score": 0.0,
    "epsilon": 0.10821408796484333
  },
  {
    "episode": 4200,
    "train_reward": -0.10999999999999954,
    "train_steps": 48,
    "eval_score": 0.0,
    "epsilon": 0.09791370725967229
  },
  {
    "episode": 4400,
    "train_reward": -1.4900000000000018,
    "train_steps": 150,
    "eval_score": 0.0,
    "epsilon": 0.0885937704566476
  },
  {
    "episode": 4600,
    "train_reward": -7.5400000000000045,
    "train_steps": 223,
    "eval_score": 0.0,
    "epsilon": 0.08016095379689364
  },
  {
    "episode": 4800,
    "train_reward": -3.1800000000000055,
    "train_steps": 208,
    "eval_score": 0.0,
    "epsilon": 0.07253081656313645
  },
  {
    "episode": 5000,
    "train_reward": 0.8399999999999983,
    "train_steps": 82,
    "eval_score": 0.0,
    "epsilon": 0.06562695554552156
  }
]