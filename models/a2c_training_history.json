[
  {
    "episode": 100,
    "train_reward": -6.59,
    "train_steps": 36,
    "eval_score": 0.0
  },
  {
    "episode": 200,
    "train_reward": -4.390000000000001,
    "train_steps": 53,
    "eval_score": 0.0
  },
  {
    "episode": 300,
    "train_reward": -5.989999999999999,
    "train_steps": 12,
    "eval_score": 0.0
  },
  {
    "episode": 400,
    "train_reward": -5.639999999999999,
    "train_steps": 19,
    "eval_score": 0.0
  },
  {
    "episode": 500,
    "train_reward": -3.8899999999999997,
    "train_steps": 12,
    "eval_score": 0.0
  },
  {
    "episode": 600,
    "train_reward": -4.880000000000001,
    "train_steps": 54,
    "eval_score": 0.0
  },
  {
    "episode": 700,
    "train_reward": -0.9400000000000002,
    "train_steps": 20,
    "eval_score": 0.0
  },
  {
    "episode": 800,
    "train_reward": -3.6399999999999997,
    "train_steps": 23,
    "eval_score": 0.2
  },
  {
    "episode": 900,
    "train_reward": -1.0700000000000007,
    "train_steps": 34,
    "eval_score": 0.2
  },
  {
    "episode": 1000,
    "train_reward": -0.6700000000000008,
    "train_steps": 36,
    "eval_score": 0.2
  },
  {
    "episode": 1100,
    "train_reward": -2.2399999999999993,
    "train_steps": 93,
    "eval_score": 0.2
  },
  {
    "episode": 1200,
    "train_reward": -2.7800000000000002,
    "train_steps": 36,
    "eval_score": 0.2
  },
  {
    "episode": 1300,
    "train_reward": -5.079999999999999,
    "train_steps": 40,
    "eval_score": 0.2
  },
  {
    "episode": 1400,
    "train_reward": -1.7800000000000022,
    "train_steps": 139,
    "eval_score": 0.2
  },
  {
    "episode": 1500,
    "train_reward": -7.239999999999993,
    "train_steps": 104,
    "eval_score": 0.2
  },
  {
    "episode": 1600,
    "train_reward": -4.44,
    "train_steps": 34,
    "eval_score": 0.2
  },
  {
    "episode": 1700,
    "train_reward": 3.01,
    "train_steps": 9,
    "eval_score": 0.2
  },
  {
    "episode": 1800,
    "train_reward": -5.99,
    "train_steps": 54,
    "eval_score": 0.2
  },
  {
    "episode": 1900,
    "train_reward": 3.9099999999999993,
    "train_steps": 36,
    "eval_score": 0.2
  },
  {
    "episode": 2000,
    "train_reward": -3.3899999999999997,
    "train_steps": 13,
    "eval_score": 0.2
  },
  {
    "episode": 2100,
    "train_reward": -1.2200000000000004,
    "train_steps": 39,
    "eval_score": 0.2
  },
  {
    "episode": 2200,
    "train_reward": -4.239999999999997,
    "train_steps": 47,
    "eval_score": 0.2
  },
  {
    "episode": 2300,
    "train_reward": 0.060000000000000275,
    "train_steps": 22,
    "eval_score": 0.2
  },
  {
    "episode": 2400,
    "train_reward": -5.829999999999999,
    "train_steps": 83,
    "eval_score": 0.2
  },
  {
    "episode": 2500,
    "train_reward": -4.589999999999999,
    "train_steps": 19,
    "eval_score": 0.2
  },
  {
    "episode": 2600,
    "train_reward": -0.7900000000000011,
    "train_steps": 56,
    "eval_score": 0.4
  },
  {
    "episode": 2700,
    "train_reward": -6.9899999999999975,
    "train_steps": 52,
    "eval_score": 0.4
  },
  {
    "episode": 2800,
    "train_reward": -0.5400000000000003,
    "train_steps": 46,
    "eval_score": 0.4
  },
  {
    "episode": 2900,
    "train_reward": -3.1400000000000006,
    "train_steps": 45,
    "eval_score": 0.4
  },
  {
    "episode": 3000,
    "train_reward": -0.5900000000000005,
    "train_steps": 27,
    "eval_score": 0.4
  },
  {
    "episode": 3100,
    "train_reward": -5.74,
    "train_steps": 107,
    "eval_score": 0.4
  },
  {
    "episode": 3200,
    "train_reward": -2.620000000000001,
    "train_steps": 80,
    "eval_score": 0.4
  },
  {
    "episode": 3300,
    "train_reward": -0.24000000000000066,
    "train_steps": 55,
    "eval_score": 0.4
  },
  {
    "episode": 3400,
    "train_reward": -5.329999999999992,
    "train_steps": 181,
    "eval_score": 0.4
  },
  {
    "episode": 3500,
    "train_reward": -5.520000000000002,
    "train_steps": 71,
    "eval_score": 0.4
  },
  {
    "episode": 3600,
    "train_reward": -7.839999999999997,
    "train_steps": 65,
    "eval_score": 0.4
  },
  {
    "episode": 3700,
    "train_reward": 3.5600000000000005,
    "train_steps": 29,
    "eval_score": 0.4
  },
  {
    "episode": 3800,
    "train_reward": -3.6899999999999924,
    "train_steps": 150,
    "eval_score": 0.4
  },
  {
    "episode": 3900,
    "train_reward": -0.21999999999999953,
    "train_steps": 146,
    "eval_score": 0.4
  },
  {
    "episode": 4000,
    "train_reward": -1.4300000000000002,
    "train_steps": 136,
    "eval_score": 0.4
  },
  {
    "episode": 4100,
    "train_reward": 1.4600000000000029,
    "train_steps": 71,
    "eval_score": 0.4
  },
  {
    "episode": 4200,
    "train_reward": -4.07,
    "train_steps": 72,
    "eval_score": 0.4
  },
  {
    "episode": 4300,
    "train_reward": 0.8199999999999996,
    "train_steps": 39,
    "eval_score": 0.4
  },
  {
    "episode": 4400,
    "train_reward": -1.2399999999999973,
    "train_steps": 95,
    "eval_score": 0.4
  },
  {
    "episode": 4500,
    "train_reward": -6.86,
    "train_steps": 88,
    "eval_score": 0.4
  },
  {
    "episode": 4600,
    "train_reward": 3.16,
    "train_steps": 24,
    "eval_score": 0.4
  },
  {
    "episode": 4700,
    "train_reward": -2.2800000000000002,
    "train_steps": 66,
    "eval_score": 0.4
  },
  {
    "episode": 4800,
    "train_reward": -3.5199999999999996,
    "train_steps": 107,
    "eval_score": 0.2
  },
  {
    "episode": 4900,
    "train_reward": 0.10999999999999877,
    "train_steps": 62,
    "eval_score": 0.2
  },
  {
    "episode": 5000,
    "train_reward": 1.3699999999999986,
    "train_steps": 62,
    "eval_score": 0.2
  },
  {
    "episode": 5100,
    "train_reward": 1.2599999999999996,
    "train_steps": 16,
    "eval_score": 0.2
  },
  {
    "episode": 5200,
    "train_reward": 1.5200000000000007,
    "train_steps": 62,
    "eval_score": 0.2
  },
  {
    "episode": 5300,
    "train_reward": -1.4800000000000006,
    "train_steps": 71,
    "eval_score": 0.2
  },
  {
    "episode": 5400,
    "train_reward": -1.4700000000000004,
    "train_steps": 29,
    "eval_score": 0.2
  },
  {
    "episode": 5500,
    "train_reward": 4.730000000000001,
    "train_steps": 59,
    "eval_score": 0.2
  },
  {
    "episode": 5600,
    "train_reward": 1.8300000000000012,
    "train_steps": 43,
    "eval_score": 0.2
  },
  {
    "episode": 5700,
    "train_reward": 4.86,
    "train_steps": 19,
    "eval_score": 0.2
  },
  {
    "episode": 5800,
    "train_reward": -3.6800000000000006,
    "train_steps": 94,
    "eval_score": 0.2
  },
  {
    "episode": 5900,
    "train_reward": -4.2700000000000005,
    "train_steps": 44,
    "eval_score": 0.2
  },
  {
    "episode": 6000,
    "train_reward": -1.7099999999999997,
    "train_steps": 35,
    "eval_score": 0.2
  },
  {
    "episode": 6100,
    "train_reward": -0.33000000000000007,
    "train_steps": 29,
    "eval_score": 0.2
  },
  {
    "episode": 6200,
    "train_reward": 3.2500000000000018,
    "train_steps": 73,
    "eval_score": 0.2
  },
  {
    "episode": 6300,
    "train_reward": 3.7600000000000007,
    "train_steps": 21,
    "eval_score": 0.2
  },
  {
    "episode": 6400,
    "train_reward": 0.8599999999999985,
    "train_steps": 74,
    "eval_score": 0.2
  },
  {
    "episode": 6500,
    "train_reward": 4.23,
    "train_steps": 45,
    "eval_score": 0.2
  },
  {
    "episode": 6600,
    "train_reward": -3.030000000000001,
    "train_steps": 28,
    "eval_score": 0.2
  },
  {
    "episode": 6700,
    "train_reward": 0.9200000000000008,
    "train_steps": 29,
    "eval_score": 0.2
  },
  {
    "episode": 6800,
    "train_reward": -0.69,
    "train_steps": 31,
    "eval_score": 0.2
  },
  {
    "episode": 6900,
    "train_reward": -7.870000000000001,
    "train_steps": 167,
    "eval_score": 0.0
  },
  {
    "episode": 7000,
    "train_reward": 2.17,
    "train_steps": 70,
    "eval_score": 0.0
  },
  {
    "episode": 7100,
    "train_reward": 1.3300000000000003,
    "train_steps": 45,
    "eval_score": 0.0
  },
  {
    "episode": 7200,
    "train_reward": 3.01,
    "train_steps": 9,
    "eval_score": 0.0
  },
  {
    "episode": 7300,
    "train_reward": 2.6899999999999995,
    "train_steps": 36,
    "eval_score": 0.0
  },
  {
    "episode": 7400,
    "train_reward": 2.9499999999999993,
    "train_steps": 68,
    "eval_score": 0.0
  },
  {
    "episode": 7500,
    "train_reward": -2.4300000000000006,
    "train_steps": 36,
    "eval_score": 0.0
  },
  {
    "episode": 7600,
    "train_reward": 0.6900000000000002,
    "train_steps": 34,
    "eval_score": 0.0
  },
  {
    "episode": 7700,
    "train_reward": 3.01,
    "train_steps": 9,
    "eval_score": 0.0
  },
  {
    "episode": 7800,
    "train_reward": -5.420000000000001,
    "train_steps": 29,
    "eval_score": 0.0
  },
  {
    "episode": 7900,
    "train_reward": 0.13999999999999901,
    "train_steps": 55,
    "eval_score": 0.0
  },
  {
    "episode": 8000,
    "train_reward": -0.17000000000000037,
    "train_steps": 65,
    "eval_score": 0.0
  },
  {
    "episode": 8100,
    "train_reward": 2.0900000000000007,
    "train_steps": 91,
    "eval_score": 0.0
  },
  {
    "episode": 8200,
    "train_reward": -2.419999999999999,
    "train_steps": 58,
    "eval_score": 0.0
  },
  {
    "episode": 8300,
    "train_reward": -0.2700000000000007,
    "train_steps": 40,
    "eval_score": 0.0
  },
  {
    "episode": 8400,
    "train_reward": -9.510000000000003,
    "train_steps": 74,
    "eval_score": 0.0
  },
  {
    "episode": 8500,
    "train_reward": -0.32000000000000006,
    "train_steps": 27,
    "eval_score": 0.0
  },
  {
    "episode": 8600,
    "train_reward": -1.130000000000002,
    "train_steps": 68,
    "eval_score": 0.0
  },
  {
    "episode": 8700,
    "train_reward": 2.51,
    "train_steps": 8,
    "eval_score": 0.0
  },
  {
    "episode": 8800,
    "train_reward": 2.3600000000000003,
    "train_steps": 14,
    "eval_score": 0.0
  },
  {
    "episode": 8900,
    "train_reward": 0.27999999999999936,
    "train_steps": 40,
    "eval_score": 0.0
  },
  {
    "episode": 9000,
    "train_reward": -0.51,
    "train_steps": 113,
    "eval_score": 0.0
  },
  {
    "episode": 9100,
    "train_reward": -2.1499999999999995,
    "train_steps": 53,
    "eval_score": 0.0
  },
  {
    "episode": 9200,
    "train_reward": 2.2900000000000027,
    "train_steps": 104,
    "eval_score": 0.0
  },
  {
    "episode": 9300,
    "train_reward": 0.879999999999999,
    "train_steps": 80,
    "eval_score": 0.0
  },
  {
    "episode": 9400,
    "train_reward": -3.2200000000000006,
    "train_steps": 39,
    "eval_score": 0.0
  },
  {
    "episode": 9500,
    "train_reward": 2.5800000000000027,
    "train_steps": 55,
    "eval_score": 0.0
  },
  {
    "episode": 9600,
    "train_reward": -1.9300000000000008,
    "train_steps": 108,
    "eval_score": 0.0
  },
  {
    "episode": 9700,
    "train_reward": 3.6800000000000024,
    "train_steps": 53,
    "eval_score": 0.0
  },
  {
    "episode": 9800,
    "train_reward": -3.4699999999999998,
    "train_steps": 100,
    "eval_score": 0.0
  },
  {
    "episode": 9900,
    "train_reward": 1.7100000000000002,
    "train_steps": 40,
    "eval_score": 0.0
  },
  {
    "episode": 10000,
    "train_reward": -0.8699999999999992,
    "train_steps": 111,
    "eval_score": 0.0
  }
]